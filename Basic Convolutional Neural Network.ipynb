{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to Convolutional Neural Network: Deep Learning\n",
    "\n",
    "\n",
    "## Details\n",
    "- This covers basic math tools, artificial neural network, multilayered perceptrons, backpropagation, deep convolutional neural network. The algorithms are applied to linear regression and image classification.\n",
    "- Textbook: Deep Learning Book by Ian Goodfellow, Yoshua Bengio and Aaron Courville\n",
    "\n",
    "\n",
    "\n",
    "## References\n",
    "- https://pytorch.org/\n",
    "- https://github.com/hunkim/PyTorchZeroToAll\n",
    "- https://towardsdatascience.com/how-to-teach-a-computer-to-see-with-convolutional-neural-networks-96c120827cd1\n",
    "- https://rohanvarma.me/Neural-Net/\n",
    "- https://excelsior-cjh.tistory.com/79\n",
    "- http://aikorea.org/cs231n/convolutional-networks/\n",
    "- http://taewan.kim/post/cnn/\n",
    "- http://cs231n.github.io/convolutional-networks/\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolutional Neural Network\n",
    "---\n",
    "![대체 텍스트](https://cdn-images-1.medium.com/max/800/0*-1Pad7loK_dFOUvS.png)\n",
    "- We are going to implement Convolutional Neural Network\n",
    "- It has two convolutional layers and two pooling layers\n",
    "\n",
    "Let's import required python package\n",
    "\n",
    "Here, ``torchvision`` module provides useful benchmark datasets and image transfromation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 1. Module Import '''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define device configuration (CPU Computation or GPU Computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "''' 2. Define device '''\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 3. Configure hyperparameters '''\n",
    "num_epochs = 10\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download MNIST dataset\n",
    "You can check the number of dataset by printing ```len(dataset)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 60000\n",
      "Number of test images: 10000\n"
     ]
    }
   ],
   "source": [
    "''' 4. Download MNIST dataset '''\n",
    "# download the MNIST dataset and\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "print('Number of train images: {}'.format(len(train_dataset)))\n",
    "print('Number of test images: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```torch.utils.data.DataLoader``` shuffles the training data and devides the entire data with ```batch_size```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 5. Load the data through dataloader '''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check the size of input tensor and label\n",
    "- Inputs: ``[batch_size, channel, width, height]``\n",
    "- Labels: ``[batch_size]``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([100, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([100]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "''' 6. Checking data (1) '''\n",
    "for X_train, y_train in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 7. Checking data (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "\n",
    "for i in range(10): # Watching just 10 images\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Usage of Conv2d Module**\n",
    "\n",
    "- ``torch.nn.Conv2d(in_channels, out_channels, kernal_size, stride, padding)``\n",
    "-  ``in_channels``  : number of channels of input\n",
    "- ``out_channels`` : number of channels of output\n",
    "\n",
    "**Usage of MaxPool2d Module**\n",
    "\n",
    "- ``torch.nn.MaxPool2d(kernel_size, stride)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 8. Building simple CNN '''\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # Linear model (width*height*channel of the last feature map, Number of class)\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        flatten = out.view(out.size(0), -1)  # Flatten\n",
    "        # flatten = out.reshape(out.size(0), -1) # We can also use '.reshape'\n",
    "        score = self.fc(flatten) # Score\n",
    "        prob = F.softmax(score) # Probability\n",
    "        return prob\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the ``criterion`` (Loss) with the ``torch.nn.CrossEntropyLoss()``\n",
    "\n",
    "Define the ``optimizer`` with ``torch.optim.SGD()`` (Stochastic Gradient Descent) which is a kind of Gradient Descent Algorithm\n",
    "- It takes two inputs ``model.parameters()`` and ``lr``\n",
    "- ``model.parameters()`` refers to the learnable parameters of model\n",
    "- ``lr`` refers to the learning rate ($\\alpha$)\n",
    "\n",
    "You can check the number of weights (parameters)\n",
    "You can print the structure of the model by using simple code ``print(model)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Number of parameters: 28938\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "''' 8. Configure Optimizer, Objective function '''\n",
    "model = ConvNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# You can usu another method by just changing name as below\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Also we can check entire number of parameters and the size of each layer\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in model.parameters())))\n",
    "for p in model.parameters():\n",
    "    print(p.size())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 9. The method for model training '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        # https://tutorials.pytorch.kr/recipes/recipes/save_load_across_devices.html#cpu-gpu\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Printing the result at the specific interval\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx, len(train_loader), 100. * batch_idx / len(train_loader),\n",
    "                loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' 10. The method for testing model '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()    # The item() method extracts the criterion’s value as a Python float.\n",
    "            prediction = output.max(1, keepdim = True)[1]   # max (at pytorch): print out maximum value by [0] and argmax by [1]\n",
    "            # The a above is same as ' prediction = torch.max(ouput, 1, keepdim = True)[1] '\n",
    "            # print out the biggest value's index of the each tensor in 'output'\n",
    "            # output 내의 각 tensor 중, 가장 큰 index를 추출\n",
    "\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            # prediction.eq(data)는 prediction배열과 data가 일치하느냐를 검사\n",
    "            # prediction.eq(data) checks whether list of prediction and data match.\n",
    "            # 그 뒤에 .sum()을 붙여서 일치하는 것들의 개수 합을 출력\n",
    "            # The sum of the number of matches is printed out by appending .sum()\n",
    "\n",
    "            # view_as() : View this tensor as the same size as other\n",
    "            # label.view_as(prediction) is equivalent to label.view(prediction.size())\n",
    "            # label을 prediction의 사이즈로 출력\n",
    "            # print out the label as the same size as prediction\n",
    "\n",
    "\n",
    "    test_loss /= (len(test_loader.dataset) / batch_size) # 'a /= b' is equal to 'a = a/b\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-b414d071f343>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = F.softmax(score) # Probability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/600 (0%)]\tTrain Loss: 2.302807\n",
      "Train Epoch: 1 [100/600 (17%)]\tTrain Loss: 2.286443\n",
      "Train Epoch: 1 [200/600 (33%)]\tTrain Loss: 1.868700\n",
      "Train Epoch: 1 [300/600 (50%)]\tTrain Loss: 1.667977\n",
      "Train Epoch: 1 [400/600 (67%)]\tTrain Loss: 1.616652\n",
      "Train Epoch: 1 [500/600 (83%)]\tTrain Loss: 1.631576\n",
      "\n",
      "[EPOCH: 1/10], \tTest Loss: 1.6179, \tTest Accuracy: 85.02 % \n",
      "\n",
      "Train Epoch: 2 [0/600 (0%)]\tTrain Loss: 1.656109\n",
      "Train Epoch: 2 [100/600 (17%)]\tTrain Loss: 1.648123\n",
      "Train Epoch: 2 [200/600 (33%)]\tTrain Loss: 1.578452\n",
      "Train Epoch: 2 [300/600 (50%)]\tTrain Loss: 1.614972\n",
      "Train Epoch: 2 [400/600 (67%)]\tTrain Loss: 1.529801\n",
      "Train Epoch: 2 [500/600 (83%)]\tTrain Loss: 1.515223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-72ce8b0d06b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m''' 11. Train the model and check the test results'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     print(\"\\n[EPOCH: {}/{}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
      "\u001b[1;32m<ipython-input-20-687e6858531e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \"\"\"\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' 11. Train the model and check the test results'''\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 100)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}/{}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, num_epochs, test_loss, test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Lable: 4\n",
      "Model output: tensor([[1.6010e-12, 5.2266e-08, 1.3108e-11, 1.6723e-08, 9.9997e-01, 5.6010e-07,\n",
      "         2.7211e-06, 3.3138e-09, 3.3014e-06, 2.4007e-05]])\n",
      "Argmax of model output: tensor([[False, False, False, False,  True, False, False, False, False, False]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-b414d071f343>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = F.softmax(score) # Probability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' We can check the prediction result of CNN model is equal to image label.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 12. Check the output after training '''\n",
    "# Torch tensor to numpy array\n",
    "image_tensor, image_label = train_dataset.__getitem__(random.randint(0, len(train_dataset)))\n",
    "model_input = image_tensor.unsqueeze(dim=0).to(device)\n",
    "model_output = model(model_input)\n",
    "\n",
    "print(f'Image Lable: {image_label}')\n",
    "print('Model output: {}'.format(model_output.data))\n",
    "print('Argmax of model output: {}'.format(model_output == torch.max(model_output)))\n",
    "\n",
    "''' We can check the prediction result of CNN model is equal to image label.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
